{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95c6eb01",
   "metadata": {},
   "source": [
    "# CacheBackedEmbeddings\n",
    "\n",
    "- Author: [byoon](https://github.com/acho98)\n",
    "- Design: []()\n",
    "- Peer Review: [ro__o_jun](https://github.com/ro-jun)\n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/08-EMBEDDING/02-CacheBackedEmbeddings.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239937-lesson-2-sub-graphs)\n",
    "\n",
    "## Overview\n",
    "\n",
    "Embeddings can be stored or temporarily cached to avoid recalculation.\n",
    "\n",
    "Caching embeddings can be done using `CacheBackedEmbeddings`. A cache-backed embedder is a wrapper around an embedder that caches embeddings in a key-value store. The text is hashed, and the hash is used as a key in the cache.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environement Setup](#environment-setup)\n",
    "- [Using Embeddings with LocalFileStore (Persistent Storage)](#using-embeddings-with-localfilestore-persistent-storage)\n",
    "- [Using InMemoryByteStore (Non-Persistent)](#using-inmemorybytestore-non-persistent)\n",
    "\n",
    "\n",
    "### References\n",
    "\n",
    "- [CacheBackedEmbeddings](https://python.langchain.com/api_reference/langchain/embeddings/langchain.embeddings.cache.CacheBackedEmbeddings.html)\n",
    "- [InMemoryByteStore](https://python.langchain.com/api_reference/core/stores/langchain_core.stores.InMemoryByteStore.html)\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2b0a9c",
   "metadata": {},
   "source": [
    "## Environment-setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
    "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ee46e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc4347eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langchain\",\n",
    "        \"langchain_community\",\n",
    "        \"langchain_openai\",\n",
    "        \"faiss-cpu\"\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2f8a43",
   "metadata": {},
   "source": [
    "Configuration file for managing API keys as environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecc17bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"CacheBackedEmbeddings\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12cc0f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6667b9ca",
   "metadata": {},
   "source": [
    "Check and create the ./cache/ directory for persistent storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bc05711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"./cache/\", exist_ok=True)\n",
    "print(os.path.exists(\"./cache/\"))  # Check if the directory exists\n",
    "print(os.access(\"./cache/\", os.W_OK))  # Check if the directory is writable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf94c21a",
   "metadata": {},
   "source": [
    "## Using Embeddings with LocalFileStore (Persistent Storage)\n",
    "\n",
    "The primary supported method for initializing `CacheBackedEmbeddings` is `from_bytes_store`.  \n",
    "\n",
    "It accepts the following parameters:\n",
    "\n",
    "- `underlying_embeddings`: The embedder is used for generating embeddings.\n",
    "- `document_embedding_cache`: One of the `ByteStore` implementations for caching document embeddings.\n",
    "- `namespace`: (Optional, default is `\"\"`) A namespace is used for the document cache. This is utilized to avoid conflicts with other caches. For example, set it to the name of the embedding model being used.\n",
    "\n",
    "**Note**: It is important to set the `namespace` parameter to avoid conflicts when the same text is embedded using different embedding models.\n",
    "\n",
    "First, let's look at an example of storing embeddings using the local file system and retrieving them with the FAISS vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a6d2d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.storage import LocalFileStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "\n",
    "# Configure basic embeddings using OpenAI embeddings\n",
    "underlying_embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Set up a local file storage\n",
    "store = LocalFileStore(\"./cache/\")\n",
    "\n",
    "# Create embeddings with caching support\n",
    "cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "    underlying_embeddings=underlying_embeddings, \n",
    "    document_embedding_cache=store, \n",
    "    namespace=underlying_embeddings.model, # Create a cache-backed embedder using the base embedding and storage\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabd8860",
   "metadata": {},
   "source": [
    "The cache is empty prior to embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8efd6aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(store.yield_keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a873ccce",
   "metadata": {},
   "source": [
    "Load the document, split it into chunks, embed each chunk and load it into the vector store.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "044e6873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "raw_documents = TextLoader(\"./data/state_of_the_union.txt\", encoding=\"utf-8\").load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b37482",
   "metadata": {},
   "source": [
    "Create FAISS database from documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1442c979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 105 ms, sys: 14.3 ms, total: 119 ms\n",
      "Wall time: 1.49 s\n"
     ]
    }
   ],
   "source": [
    "%time db = FAISS.from_documents(documents, cached_embedder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487b6402",
   "metadata": {},
   "source": [
    "If we try to create the vector store again, it'll be much faster since it does not need to re-compute any embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7914f363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.8 ms, sys: 3.23 ms, total: 25 ms\n",
      "Wall time: 23.8 ms\n"
     ]
    }
   ],
   "source": [
    "# Create FAISS database using cached embeddings\n",
    "%time db2 = FAISS.from_documents(documents, cached_embedder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078cdc9c",
   "metadata": {},
   "source": [
    "Here are some of the embeddings that got created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ed5d525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text-embedding-3-small464862c8-03d2-5854-b32c-65a075e612a2',\n",
       " 'text-embedding-3-small6d6cb8fc-721a-5a4c-bfe9-c83d2920c2bb',\n",
       " 'text-embedding-3-small5990258b-0781-5651-8444-c69cb5b6da3d',\n",
       " 'text-embedding-3-small01dbc21f-5e4c-5fb5-8d13-517dbe7a32d4',\n",
       " 'text-embedding-3-small704c76af-3696-5383-9858-6585616669ef']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(store.yield_keys())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf59fa6",
   "metadata": {},
   "source": [
    "## Using `InMemoryByteStore` (Non-Persistent)\n",
    "\n",
    "To use a different `ByteStore`, simply specify the desired `ByteStore` when creating the `CacheBackedEmbeddings`.\n",
    "\n",
    "Below is an example of creating the same cached embedding object using the non-persistent `InMemoryByteStore`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a58c94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.storage import InMemoryByteStore\n",
    "\n",
    "# Create an in-memory byte store\n",
    "store = InMemoryByteStore()\n",
    "\n",
    "underlying_embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "    underlying_embeddings, store, namespace=underlying_embeddings.model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37938302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 87.4 ms, sys: 8.58 ms, total: 96 ms\n",
      "Wall time: 1.14 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['text-embedding-3-small305efb5c-3f01-5657-bcf2-2b92fb1747ca',\n",
       " 'text-embedding-3-small01dbc21f-5e4c-5fb5-8d13-517dbe7a32d4',\n",
       " 'text-embedding-3-smalla5ef11e4-0474-5725-8d80-81c91943b37f',\n",
       " 'text-embedding-3-small6d6cb8fc-721a-5a4c-bfe9-c83d2920c2bb',\n",
       " 'text-embedding-3-small81426526-23fe-58be-9e84-6c7c72c8ca9a']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time db = FAISS.from_documents(documents, cached_embedder)  \n",
    "list(store.yield_keys())[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-opentutorial-VHYpHY_j-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
