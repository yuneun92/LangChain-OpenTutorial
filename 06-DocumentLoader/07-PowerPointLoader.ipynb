{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Microsoft PowerPoint\n",
        "\n",
        "- Author: [Kane](https://github.com/HarryKane11)\n",
        "- Design: [Kane](https://github.com/HarryKane11)\n",
        "- Peer Review: [architectyou](https://github.com/architectyou), [jhboyo](https://github.com/jhboyo), [fastjw](https://github.com/fastjw)\n",
        "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/06-DocumentLoader/07-PowerPoint-Loader.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/06-DocumentLoader/07-PowerPoint-Loader.ipynb)\n",
        "\n",
        "## Overview\n",
        "\n",
        "[Microsoft PowerPoint](https://en.wikipedia.org/wiki/Microsoft_PowerPoint) is a presentation program developed by Microsoft.\n",
        "\n",
        "This tutorial demonstrates two different approaches to process PowerPoint documents for downstream use:\n",
        "1. Using `Unstructured` to load and parse PowerPoint files into document elements\n",
        "2. Using `MarkItDown` to convert PowerPoint files into markdown format and LangChain Document objects\n",
        "\n",
        "Both methods enable effective text extraction and processing, with different strengths for various use cases.\n",
        "\n",
        "### Table of Contents\n",
        "\n",
        "- [Overview](#overview)\n",
        "- [Environment Setup](#environment-setup)\n",
        "- [Converting PPTX to Langchain Documents Using Unstructured](#converting-pptx-to-langchain-documents-using-unstructured)\n",
        "- [Converting PPTX to Langchain Documents Using MarkItDown](#converting-pptx-to-langchain-documents-using-markitdown)\n",
        "\n",
        "### References\n",
        "\n",
        "- [Unstructured: official documentation](https://docs.unstructured.io/open-source/core-functionality/overview)\n",
        "- [MarkItDown: GitHub Repository](https://github.com/microsoft/markitdown)\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "\n",
        "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
        "\n",
        "**[Note]**\n",
        "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
        "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install langchain-opentutorial "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "from langchain_opentutorial import package\n",
        "\n",
        "package.install(\n",
        "    [\n",
        "        \"langchain-community\",\n",
        "        \"langchain-core\",\n",
        "        \"unstructured\",\n",
        "        \"markitdown\"\n",
        "    ],\n",
        "    verbose=False,\n",
        "    upgrade=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Converting PPTX to Langchain Documents Using Unstructured\n",
        "\n",
        "[Unstructured](https://github.com/Unstructured-IO/unstructured) is a robust document processing library that excels at converting various document formats into clean, structured text. <br/>It is well integrated with LangChain's ecosystem and provides reliable document parsing capabilities. \n",
        "\n",
        "The library includes:\n",
        "\n",
        "- Local processing with open-source package\n",
        "- Remote processing via Unstructured API\n",
        "- Comprehensive document format support\n",
        "- Built-in OCR capabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import UnstructuredPowerPointLoader\n",
        "\n",
        "# Initialize UnstructuredPowerPointLoader\n",
        "loader = UnstructuredPowerPointLoader(\"data/07-ppt-loader-sample.pptx\")\n",
        "\n",
        "# Load PowerPoint document\n",
        "docs = loader.load()\n",
        "\n",
        "# Print number of loaded documents\n",
        "print(len(docs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Natural Language Processing with Deep Learning\n",
            "\n",
            "CS224N/Ling284\n",
            "\n",
            "Christopher Manning\n",
            "\n",
            "Lecture 2: Word\n"
          ]
        }
      ],
      "source": [
        "print(docs[0].page_content[:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`Unstructured` generates various \"elements\" for different **chunks** of text.\n",
        "\n",
        "By default, they are combined and returned as a single document, but elements can be easily separated by specifying `mode=\"elements\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "498\n"
          ]
        }
      ],
      "source": [
        "# Create UnstructuredPowerPointLoader with elements mode\n",
        "loader = UnstructuredPowerPointLoader(\"data/07-ppt-loader-sample.pptx\", mode=\"elements\")\n",
        "\n",
        "# Load PowerPoint elements\n",
        "docs = loader.load()\n",
        "\n",
        "# Print number of elements extracted\n",
        "print(len(docs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'assets/sample.pptx', 'category_depth': 0, 'file_directory': 'assets', 'filename': 'sample.pptx', 'last_modified': '2024-12-30T01:00:34', 'page_number': 1, 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'Title', 'element_id': 'aa75080e026117468068eec241cf786f'}, page_content='Natural Language Processing with Deep Learning')"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='Natural Language Processing with Deep Learning' metadata={'source': 'assets/sample.pptx', 'category_depth': 0, 'file_directory': 'assets', 'filename': 'sample.pptx', 'last_modified': '2024-12-30T01:00:34', 'page_number': 1, 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'Title', 'element_id': 'aa75080e026117468068eec241cf786f'}\n",
            "Content: Natural Language Processing with Deep Learning\n",
            "Metadata: {'source': 'assets/sample.pptx', 'category_depth': 0, 'file_directory': 'assets', 'filename': 'sample.pptx', 'last_modified': '2024-12-30T01:00:34', 'page_number': 1, 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'Title', 'element_id': 'aa75080e026117468068eec241cf786f'}\n"
          ]
        }
      ],
      "source": [
        "# Get and display the first element\n",
        "first_element = docs[0]\n",
        "print(first_element)\n",
        "\n",
        "# To see its metadata and content separately, you could do:\n",
        "print(\"Content:\", first_element.page_content)\n",
        "print(\"Metadata:\", first_element.metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Element 1/498\n",
            "Category: Title\n",
            "==================================================\n",
            "Content:\n",
            "Natural Language Processing with Deep Learning\n",
            "==================================================\n",
            "\n",
            "Element 2/498\n",
            "Category: Title\n",
            "==================================================\n",
            "Content:\n",
            "CS224N/Ling284\n",
            "==================================================\n",
            "\n",
            "Element 3/498\n",
            "Category: Title\n",
            "==================================================\n",
            "Content:\n",
            "Christopher Manning\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Print elements with formatted output and enumerate for easy reference\n",
        "for idx, doc in enumerate(docs[:3], 1):\n",
        "    print(f\"\\nElement {idx}/{len(docs)}\")\n",
        "    print(f\"Category: {doc.metadata['category']}\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Content:\\n{doc.page_content.strip()}\")\n",
        "    print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Converting PPTX to Langchain Documents Using MarkItDown\n",
        "\n",
        "[`MarkItDown`](https://github.com/microsoft/markitdown \"Visit the GitHub page\")\n",
        " is an open-source library by Microsoft that converts unstructured documents into structured Markdown, a format that LLMs can easily process and understand. This makes it particularly valuable for RAG (Retrieval Augmented Generation) systems by enabling clean, semantic text representation.\n",
        "\n",
        "Supporting formats like PDF, PowerPoint, Word, Excel, images (with EXIF/OCR), audio (with transcription), HTML, and more, `MarkItDown` preserves semantic structure and handles complex data, such as tables, with precision. This ensures high retrieval quality and enhances LLMs' ability to extract insights from diverse content types.\n",
        "\n",
        "> ⚠️**Note**: MarkItDown does not interpret the content of images embedded in PowerPoint files. Instead, it extracts the images as-is, leaving their semantic meaning inaccessible to LLMs.\n",
        "\n",
        "For example, an object in the slide would be processed like this:\n",
        "\n",
        "`![object #](object#.jpg)`\n",
        "\n",
        "Installation is straightforward:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %pip install markitdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extracting Text from PPTX Using MarkItDown\n",
        "In this section, we'll use `MarkItDown` to:\n",
        "* Convert PowerPoint slides to markdown format\n",
        "* Preserve the semantic structure and visual formatting\n",
        "* Maintain slide numbers and titles\n",
        "* Generate clean, readable text output\n",
        "\n",
        "\n",
        "First, we need to initialize `MarkItDown` and run `convert` function to load the `.pptx` from local."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<!-- Slide number: 1 -->\n",
            "\n",
            "![object 2](object2.jpg)\n",
            "# Natural Language Processing with Deep Learning\n",
            "CS224N/Ling284\n",
            "Christopher Manning\n",
            "Lecture 2: Word Vectors, Word Senses, and Neural Classifiers\n",
            "\n",
            "<!-- Slide number: 2 -->\n",
            "# Lecture Plan\n",
            "10\n",
            "Lecture 2: Word Vectors, Word Senses, and Neural Network Classifiers\n",
            "Course organization (3 mins)\n",
            "Optimization basics (5 mins)\n",
            "Review of word2vec and looking at word vectors (12 mins)\n",
            "More on word2vec (8 mins)\n",
            "Can we capture the essence of word meaning more ef\n"
          ]
        }
      ],
      "source": [
        "from markitdown import MarkItDown\n",
        "\n",
        "md = MarkItDown()\n",
        "result = md.convert(\"data/07-ppt-loader-sample.pptx\")\n",
        "result_text = result.text_content\n",
        "print(result_text[:500])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convert markdown format to Langchain Document format\n",
        "\n",
        "The code below processes PowerPoint slides by splitting them into individual Document objects. <br/>Each slide is converted into a Langchain Document object with metadata including the `slide number` and `title`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '../99-TEMPLATE/assets/sample.pptx', 'slide_number': 1, 'slide_title': 'Natural Language Processing with Deep Learning'}, page_content='![object 2](object2.jpg)\\n# Natural Language Processing with Deep Learning\\nCS224N/Ling284\\nChristopher Manning\\nLecture 2: Word Vectors, Word Senses, and Neural Classifiers'),\n",
              " Document(metadata={'source': '../99-TEMPLATE/assets/sample.pptx', 'slide_number': 2, 'slide_title': 'Lecture Plan'}, page_content='# Lecture Plan\\n10\\nLecture 2: Word Vectors, Word Senses, and Neural Network Classifiers\\nCourse organization (3 mins)\\nOptimization basics (5 mins)\\nReview of word2vec and looking at word vectors (12 mins)\\nMore on word2vec (8 mins)\\nCan we capture the essence of word meaning more effectively by counting? (12m)\\nEvaluating word vectors (10 mins)\\nWord senses (10 mins)\\nReview of classification and how neural nets differ (10 mins)\\nIntroducing neural networks (10 mins)\\n\\nKey Goal: To be able to read and understand word embeddings papers by the end of class')]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.documents import Document\n",
        "import re\n",
        "\n",
        "# Initialize document processing for PowerPoint slides\n",
        "# Format: <!-- Slide number: X --> where X is the slide number\n",
        "\n",
        "# Split the input text into individual slides using HTML comment markers\n",
        "slides = re.split(r'<!--\\s*Slide number:\\s*(\\d+)\\s*-->', result_text)\n",
        "\n",
        "# Initialize list to store Document objects\n",
        "documents = []\n",
        "\n",
        "# Process each slide:\n",
        "# - Start from index 1 since slides[0] is empty from the initial split\n",
        "# - Step by 2 because the split result alternates between:\n",
        "#   1. slide number (odd indices)\n",
        "#   2. slide content (even indices)\n",
        "# Example: ['', '1', 'content1', '2', 'content2', '3', 'content3']\n",
        "for i in range(1, len(slides), 2):\n",
        "    # Extract slide number and content\n",
        "    slide_number = slides[i]\n",
        "    content = slides[i + 1].strip() if i + 1 < len(slides) else \"\"\n",
        "    \n",
        "    # Extract slide title from first markdown header if present\n",
        "    title_match = re.search(r'#\\s*(.+?)(?=\\n|$)', content)\n",
        "    title = title_match.group(1).strip() if title_match else \"\"\n",
        "    \n",
        "    # Create Document object with slide metadata\n",
        "    doc = Document(\n",
        "        page_content=content,\n",
        "        metadata={\n",
        "            \"source\": \"data/07-ppt-loader-sample.pptx\",\n",
        "            \"slide_number\": int(slide_number),\n",
        "            \"slide_title\": title\n",
        "        }\n",
        "    )\n",
        "    documents.append(doc)\n",
        "\n",
        "documents[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`MarkItDown` efficiently handles tables in PowerPoint slides by converting them into clean Markdown table syntax. \n",
        "\n",
        "This makes tabular data easily accessible for LLMs while preserving the original structure and formatting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Example: Window based co-occurrence matrix\n",
            "10\n",
            "Window length 1 (more common: 5–10)\n",
            "Symmetric (irrelevant whether left or right context)\n",
            "\n",
            "Example corpus:\n",
            "I like deep learning\n",
            "I like NLP\n",
            "I enjoy flying\n",
            "\n",
            "| counts | I | like | enjoy | deep | learning | NLP | flying | . |\n",
            "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
            "| I | 0 | 2 | 1 | 0 | 0 | 0 | 0 | 0 |\n",
            "| like | 2 | 0 | 0 | 1 | 0 | 1 | 0 | 0 |\n",
            "| enjoy | 1 | 0 | 0 | 0 | 0 | 0 | 1 | 0 |\n",
            "| deep | 0 | 1 | 0 | 0 | 1 | 0 | 0 | 0 |\n",
            "| learning | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 1 |\n",
            "| NLP | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 1 |\n",
            "| flying | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 1 |\n",
            "| . | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 0 |\n"
          ]
        }
      ],
      "source": [
        "print(documents[15].page_content)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langchain-opentutorial-RXtDr8w5-py3.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
