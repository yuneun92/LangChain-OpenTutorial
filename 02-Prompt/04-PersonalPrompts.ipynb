{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3FhQbSSEKAq"
      },
      "source": [
        "# Personal Prompts for LangChain\n",
        "\n",
        "- Author: [Yun Eun](https://github.com/yuneun92)\n",
        "- Design: \n",
        "- Peer Review: [jeong-wooseok](https://github.com/jeong-wooseok), [r14minji](https://github.com/r14minji)\n",
        "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/02-Prompt/04-PersonalPrompts.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/02-Prompt/04-PersonalPrompts.ipynb)\n",
        "\n",
        "## Overview\n",
        "\n",
        "This cookbook contains a comprehensive collection of specialized prompts designed for various professional domains using `LangChain`. The prompts are crafted to leverage the power of large language models while maintaining domain expertise and professional standards.\n",
        "\n",
        "> The primary goals of this project are to:\n",
        "- Provide standardized, high-quality prompts for different professional domains\n",
        "- Enable consistent and reliable outputs from language models\n",
        "- Facilitate domain-specific knowledge extraction and analysis\n",
        "- Support automated report generation and content creation\n",
        "- Maintain professional standards across various fields\n",
        "\n",
        "### Table of Contents\n",
        "\n",
        "- [Overview](##overview)\n",
        "- [Prompt Generating Tips](##prompt-generating-tips)\n",
        "- [Basic Prompts](##basic-prompts)\n",
        "- [Advanced Prompts](##advanced-prompts)\n",
        "- [Specialized Prompts](##specialized-prompts)\n",
        "- [Professional Domain Prompts](##professional-domain-prompts)\n",
        "\n",
        "### References\n",
        "\n",
        "- [Prompt Engineering Guide: Gemini](https://www.promptingguide.ai/models/gemini)\n",
        "- [Google: Prompting Guide 101](https://services.google.com/fh/files/misc/gemini-for-google-workspace-prompting-guide-101.pdf)\n",
        "- [Anthropic: Prompt Engineering - Use XML tags to structure your prompts\n",
        "](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags)\n",
        "- [Anthropic: Prompt engineering overview](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview)\n",
        "- [Anthropic: Anthropic's Prompt Engineering Interactive Tutorial](https://docs.google.com/spreadsheets/d/19jzLgRruG9kjUQNKtCg1ZjdD6l6weA6qRXG5zLIAhC8/edit?gid=1733615301#gid=1733615301)\n",
        "- [Github: prompt-eng-interactive-tutorial](https://github.com/anthropics/prompt-eng-interactive-tutorial)\n",
        "- [The Decoder: Chat GPT Guide](https://the-decoder.com/chatgpt-guide-prompt-strategies/)\n",
        "- [Dorik: How to Write Prompts for ChatGPT (with Examples)](https://dorik.com/blog/how-to-write-prompts-for-chatgpt)\n",
        "- [Coursera: How To Write ChatGPT Prompts: Your 2025 Guide](https://www.coursera.org/articles/how-to-write-chatgpt-prompts)\n",
        "- [LangSmith: Prompt Hub](https://docs.smith.langchain.com/old/hub/dev-setup)\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujWGc2x1KTAN"
      },
      "source": [
        "## Environment Setup\n",
        "\n",
        "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
        "\n",
        "**[Note]**\n",
        "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials.\n",
        "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HG2L3xhaKSIw"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install dotenv langchain-opentutorial langchain langchainhub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_ILb4kLiJ3n"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "from langchain_opentutorial import package\n",
        "\n",
        "package.install(\n",
        "    [\n",
        "        \"langsmith\",\n",
        "        \"langchain\",\n",
        "        \"langchainhub\"\n",
        "    ],\n",
        "    verbose=False,\n",
        "    upgrade=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoxdCFP7iK5Z"
      },
      "outputs": [],
      "source": [
        "# Set environment variables\n",
        "from langchain_opentutorial import set_env\n",
        "\n",
        "set_env(\n",
        "    {\n",
        "        \"OPENAI_API_KEY\": \"\",\n",
        "        # Get an API key for your Personal organization if you have not yet. The hub will not work with your non-personal organization's api key!\n",
        "        # If you already have LANGCHAIN_API_KEY set to a personal organization’s api key from LangSmith, you can skip this.\n",
        "        \"LANGCHAIN_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
        "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
        "        \"LANGCHAIN_PROJECT\": \"Personal Prompts for LangChain\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo87C1reS4rC"
      },
      "source": [
        "## Prompt Generating Tips\n",
        "\n",
        "\n",
        "### **Model Comparison at a Glance:**\n",
        "\n",
        "| Feature                | **ChatGPT**                                      | **Claude**                                      | **Gemini**                                      |\n",
        "|------------------------|--------------------------------------------------|------------------------------------------------|------------------------------------------------|\n",
        "| **Strengths**           | Conversational, logical reasoning               | Handles structured formats, logical responses  | Works well with detailed tasks and examples    |\n",
        "| **Best Practice**       | Clear, focused prompts                          | XML-style structured prompts                   | Detailed instructions and examples             |\n",
        "| **Example Use Case**    | Writing emails, casual conversations            | Analytical tasks, structured outputs           | Summaries, detailed reports, multimodal tasks  |\n",
        "\n",
        "By following these tailored tips, you can maximize the strengths of each model and achieve optimal performance in your LangChain projects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvQ5teCqwKvM"
      },
      "source": [
        "### **1. ChatGPT (OpenAI's GPT-4)**  \n",
        "ChatGPT is a powerful language model known for its conversational ability and logical reasoning.\n",
        "\n",
        "> **Prompt Tips:**\n",
        "- **Keep it Clear and Focused:**  Clearly define what you want the model to do. Don’t overload it with too much background information.\n",
        "- **Ask for a Specific Format:**  If you need the response in bullet points, tables, or paragraphs, mention it.\n",
        "- **Assign a Role:**  Tell ChatGPT who it is (e.g., \"You are a project manager\") to get more tailored answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "bGRKNlD0Ezv-",
        "outputId": "8bd62e02-1547-4a00-b092-906b77c40d93"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'You are a professional email writer. Write a polite email to a client informing them of a project delay of one month due to supply chain issues. The tone should be apologetic but confident.'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example Prompt for GPT4\n",
        "\"You are a professional email writer. Write a polite email to a client informing them of a project delay of one month due to supply chain issues. The tone should be apologetic but confident.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPoI2wEXEtZx"
      },
      "source": [
        "### **2. Claude (Anthropic's Model)**  \n",
        "Claude excels in structured thinking and understanding detailed tasks. It often works well with **XML-style formatting** for prompts.\n",
        "\n",
        "> **Prompt Tips:**\n",
        "- **Use Structured Formats:**  Use XML tags to organize the instructions, which helps Claude interpret them better.\n",
        "- **Provide Context and Examples:**  Add a clear task and examples to guide the model's response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "X-J4xElqE8GH",
        "outputId": "bb199b26-fb57-4d21-c9c3-0d9ba7632bad"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n<context>\\n  <project>\\n    <name>Website Redesign</name>\\n    <deadline>March 15, 2025</deadline>\\n  </project>\\n</context>\\n<instructions>\\n  Write an email to the client explaining the project will be delayed by one month due to supply chain issues. Apologize and propose a new deadline.\\n</instructions>\\n<example>\\n  Dear [Client Name],\\n\\n  Due to supply chain challenges, we regret to inform you that the project will be delayed. The new expected completion date is April 15, 2025. We apologize for the inconvenience and appreciate your understanding.\\n\\n  Best regards,  \\n  [Your Name]\\n</example>\\n'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example Prompt for Claude\n",
        "\"\"\"\n",
        "<context>\n",
        "  <project>\n",
        "    <name>Website Redesign</name>\n",
        "    <deadline>March 15, 2025</deadline>\n",
        "  </project>\n",
        "</context>\n",
        "<instructions>\n",
        "  Write an email to the client explaining the project will be delayed by one month due to supply chain issues. Apologize and propose a new deadline.\n",
        "</instructions>\n",
        "<example>\n",
        "  Dear [Client Name],\n",
        "\n",
        "  Due to supply chain challenges, we regret to inform you that the project will be delayed. The new expected completion date is April 15, 2025. We apologize for the inconvenience and appreciate your understanding.\n",
        "\n",
        "  Best regards,\n",
        "  [Your Name]\n",
        "</example>\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyExycWfExUW"
      },
      "source": [
        "### **3. Gemini (Google’s AI Model)**  \n",
        "Gemini is a cutting-edge multimodal AI designed to work across text, images, and other data types. It handles detailed and structured tasks effectively.\n",
        "\n",
        "> **Prompt Tips:**\n",
        "- **Be Detailed and Specific:**  Clearly explain the task and provide any necessary background details.\n",
        "- **Break Complex Tasks into Steps:**  If the task is complicated, split it into smaller, sequential steps.\n",
        "- **Add Examples:**  Providing examples helps Gemini align its output with your expectations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9MI5GzQcFFNt",
        "outputId": "9b945294-dea9-43f4-f31a-042d38b74e69"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'You are a marketing strategist. Write a 200-word summary of the key milestones achieved in a project, emphasizing the team’s performance and results. Use a professional tone.'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Exmple Prompt for Gemini\n",
        "\"You are a marketing strategist. Write a 200-word summary of the key milestones achieved in a project, emphasizing the team’s performance and results. Use a professional tone.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFfeSRoCEj4I"
      },
      "source": [
        "---\n",
        "## Basic Prompts\n",
        "\n",
        "The Basic Prompts chapter covers summarization tasks that are most commonly used across all domains. These prompts can be used individually or combined in a pipeline:\n",
        "\n",
        "\n",
        "1. **Sequential Processing**\n",
        "   ```python\n",
        "   documents → Summary Prompt → Map Prompt → Reduce Prompt → Final Output\n",
        "   ```\n",
        "\n",
        "2. **Parallel Processing**\n",
        "   ```python\n",
        "   documents → Multiple Summary Prompts (parallel)\n",
        "            → Map Prompts (parallel)\n",
        "            → Single Reduce Prompt\n",
        "            → Final Output\n",
        "   ```\n",
        "\n",
        "3. **Hybrid Processing**\n",
        "   ```python\n",
        "   documents → Summary Prompt\n",
        "            → Map Prompt (for themes)\n",
        "            → Reduce Prompt (for final synthesis)\n",
        "            → Additional Summary Prompt (for final polish)\n",
        "   ```\n",
        "\n",
        "\n",
        "\n",
        "### 1. Summary Prompt\n",
        "\n",
        "The Summary Prompt is designed to create concise, informative summaries of documents while maintaining key information and context.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5d4muPzSW06"
      },
      "outputs": [],
      "source": [
        "PROMPT_OWNER = \"eun\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jCgju8_E_V1",
        "outputId": "caac0a06-b18c-487e-b231-20c52b4e9044"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nPlease summarize the sentence according to the following REQUEST.\\nREQUEST:\\n1. Summarize the main points in bullet points.\\n2. Each summarized sentence must start with an emoji that fits the meaning of the each sentence.\\n3. Use various emojis to make the summary more interesting.\\n4. DO NOT include any unnecessary information.\\n\\nCONTEXT:\\n{context}\\n\\nSUMMARY:\"\\n')"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain import hub\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Let's upload the prompt to the LangChain Hub.\n",
        "# Don't forget to enter the LangSmith API as an environment variable.\n",
        "prompt_title = \"summarize_document\"\n",
        "\n",
        "summarize_prompt = \"\"\"\n",
        "Please summarize the sentence according to the following REQUEST.\n",
        "REQUEST:\n",
        "1. Summarize the main points in bullet points.\n",
        "2. Each summarized sentence must start with an emoji that fits the meaning of the each sentence.\n",
        "3. Use various emojis to make the summary more interesting.\n",
        "4. DO NOT include any unnecessary information.\n",
        "\n",
        "CONTEXT:\n",
        "{context}\n",
        "\n",
        "SUMMARY:\"\n",
        "\"\"\"\n",
        "prompt = PromptTemplate.from_template(summarize_prompt)\n",
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nW0KSsa-PImJ",
        "outputId": "d68ba0c0-dc69-408c-f778-6d8b67f18591"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://smith.langchain.com/prompts/summarize_document/129da0ee?organizationId=f2bffb3c-dd45-53ac-b23b-5d696451d11c'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# To upload a prompt to Hub:\n",
        "#\n",
        "# Private Repository:\n",
        "# - Simply pass the prompt title as the first argument\n",
        "# hub.push(prompt_title, prompt, new_repo_is_public=False)\n",
        "#\n",
        "# Public Repository:\n",
        "# - First create a Hub Handle at LangSmith (smith.langchain.com)\n",
        "# - Include your handle in the prompt title path\n",
        "# hub.push(f\"{PROMPT_OWNER}/{prompt_title}\", prompt, new_repo_is_public=True)\n",
        "\n",
        "hub.push(f\"{PROMPT_OWNER}/{prompt_title}\", prompt, new_repo_is_public=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pkMouSCRXsA"
      },
      "source": [
        "You can find the uploaded prompt in your `LangSmith` . Please go to the site address as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55Mcx-IBSwyK",
        "outputId": "86a2fc3a-5ae0-4223-ab76-6f189c598c12"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'eun', 'lc_hub_repo': 'summarize_document', 'lc_hub_commit_hash': '129da0ee7cc02d076cd26692334f58a4aa898f5c40916847e8d808adb31f0263'}, template='\\nPlease summarize the sentence according to the following REQUEST.\\nREQUEST:\\n1. Summarize the main points in bullet points.\\n2. Each summarized sentence must start with an emoji that fits the meaning of the each sentence.\\n3. Use various emojis to make the summary more interesting.\\n4. DO NOT include any unnecessary information.\\n\\nCONTEXT:\\n{context}\\n\\nSUMMARY:\"\\n')"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# You can import and use prompts as follows.\n",
        "prompt = hub.pull(\"eun/summarize_document:129da0ee\")\n",
        "prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tj2GziG9F9TT"
      },
      "source": [
        "### 2. Map Prompt\n",
        "\n",
        "The Map Prompt is used to extract and organize main themes from documents, creating a structured representation of the content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIX0yuk0D7xZ",
        "outputId": "1a59fcf7-5e8f-49d2-8520-a786c037e62c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['docs'], input_types={}, partial_variables={}, template='\\nYou are a helpful expert journalist in extracting the main themes from a GIVEN DOCUMENTS below.\\nPlease provide a comprehensive summary of the GIVEN DOCUMENTS in numbered list format.\\nThe summary should cover all the key points and main ideas presented in the original text, while also condensing the information into a concise and easy-to-understand format.\\nPlease ensure that the summary includes relevant details and examples that support the main ideas, while avoiding any unnecessary information or repetition.\\nThe length of the summary should be appropriate for the length and complexity of the original text, providing a clear and accurate overview without omitting any important information.\\n\\nGIVEN DOCUMENTS:\\n{docs}\\n\\nFORMAT:\\n1. main theme 1\\n2. main theme 2\\n3. main theme 3\\n...\\n\\nCAUTION:\\n- DO NOT list more than 5 main themes.\\n\\nHelpful Answer:\\n')"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain import hub\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_title = \"map-prompt\"\n",
        "\n",
        "map_prompt = \"\"\"\n",
        "You are a helpful expert journalist in extracting the main themes from a GIVEN DOCUMENTS below.\n",
        "Please provide a comprehensive summary of the GIVEN DOCUMENTS in numbered list format.\n",
        "The summary should cover all the key points and main ideas presented in the original text, while also condensing the information into a concise and easy-to-understand format.\n",
        "Please ensure that the summary includes relevant details and examples that support the main ideas, while avoiding any unnecessary information or repetition.\n",
        "The length of the summary should be appropriate for the length and complexity of the original text, providing a clear and accurate overview without omitting any important information.\n",
        "\n",
        "GIVEN DOCUMENTS:\n",
        "{docs}\n",
        "\n",
        "FORMAT:\n",
        "1. main theme 1\n",
        "2. main theme 2\n",
        "3. main theme 3\n",
        "...\n",
        "\n",
        "CAUTION:\n",
        "- DO NOT list more than 5 main themes.\n",
        "\n",
        "Helpful Answer:\n",
        "\"\"\"\n",
        "prompt = PromptTemplate.from_template(map_prompt)\n",
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "OQ3qVGX1GzrF",
        "outputId": "7cbc13c0-16f2-4b2e-f756-b10cf0e639c1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://smith.langchain.com/prompts/map-prompt/1535fbd6?organizationId=f2bffb3c-dd45-53ac-b23b-5d696451d11c'"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hub.push(prompt_title, prompt, new_repo_is_public=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxc8svsyGQfM"
      },
      "source": [
        "### 3. Reduce Prompt\n",
        "\n",
        "The Reduce Prompt combines and synthesizes multiple summaries into a single, coherent output, particularly useful for processing large document sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beKSYVn8D7xc",
        "outputId": "6f99f629-adcc-4422-d136-c0330b11dcac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['doc_summaries'], input_types={}, partial_variables={}, template='\\nYou are a helpful expert in summary writing.\\nYou are given numbered lists of summaries.\\nExtract top 10 most important insights and create a unified summary.\\n\\nLIST OF SUMMARIES:\\n{doc_summaries}\\n\\nREQUIREMENTS:\\n1. Identify key insights across summaries\\n2. Maintain coherence and flow\\n3. Eliminate redundancy\\n4. Preserve important details\\n5. Create a unified narrative\\n\\nOUTPUT FORMAT:\\n1. Main insights (bullet points)\\n2. Synthesized summary\\n3. Key takeaways\\n')"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain import hub\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_title = \"reduce-prompt\"\n",
        "\n",
        "reduce_prompt = \"\"\"\n",
        "You are a helpful expert in summary writing.\n",
        "You are given numbered lists of summaries.\n",
        "Extract top 10 most important insights and create a unified summary.\n",
        "\n",
        "LIST OF SUMMARIES:\n",
        "{doc_summaries}\n",
        "\n",
        "REQUIREMENTS:\n",
        "1. Identify key insights across summaries\n",
        "2. Maintain coherence and flow\n",
        "3. Eliminate redundancy\n",
        "4. Preserve important details\n",
        "5. Create a unified narrative\n",
        "\n",
        "OUTPUT FORMAT:\n",
        "1. Main insights (bullet points)\n",
        "2. Synthesized summary\n",
        "3. Key takeaways\n",
        "\"\"\"\n",
        "prompt = PromptTemplate.from_template(reduce_prompt)\n",
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "AQEnto5xD7xc",
        "outputId": "bd9a657e-c5e0-42fc-f1ad-4c476b196c03"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://smith.langchain.com/prompts/reduce-prompt/17ed176f?organizationId=f2bffb3c-dd45-53ac-b23b-5d696451d11c'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hub.push(prompt_title, prompt, new_repo_is_public=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdPw-wLbIq42"
      },
      "source": [
        "---\n",
        "## Advanced Prompts\n",
        "\n",
        "The Advanced Prompts chapter explores sophisticated techniques that enhance the quality and specificity of language model outputs. These prompts are designed to handle complex tasks requiring deeper analysis and more nuanced responses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYBsvlfaIqz0"
      },
      "source": [
        "### 1. Chain of Density Summarization\n",
        "\n",
        "Chain of Density Summarization iteratively refines summaries to achieve higher information density while maintaining readability and key insights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAiX_AqKD7xc"
      },
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_title = \"chain-of-density\"\n",
        "\n",
        "chain_density_prompt = \"\"\"\n",
        "Given the input text, generate increasingly dense summaries through the following steps:\n",
        "\n",
        "INPUT PARAMETERS:\n",
        "- Text: {text}\n",
        "- Iteration Count: {iterations}\n",
        "- Target Length: {length}\n",
        "\n",
        "PROCESS:\n",
        "1. Initial Summary\n",
        "2. Entity Identification\n",
        "3. Density Enhancement\n",
        "4. Quality Check\n",
        "\n",
        "OUTPUT REQUIREMENTS:\n",
        "1. Maintain consistent length\n",
        "2. Increase information density\n",
        "3. Preserve key entities\n",
        "4. Ensure readability\n",
        "\n",
        "Please provide the summary following this structure:\n",
        "\n",
        "FORMAT:\n",
        "{\n",
        "    \"initial_summary\": str,\n",
        "    \"entity_map\": list,\n",
        "    \"refined_summaries\": list,\n",
        "    \"final_summary\": str\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(chain_density_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wSVewIsdD7xd",
        "outputId": "bf8b4672-1c52-4883-9b20-696efa7a8454"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://smith.langchain.com/prompts/chain-of-density/a9eac13f?organizationId=f2bffb3c-dd45-53ac-b23b-5d696451d11c'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hub.push(prompt_title, prompt, new_repo_is_public=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RRmJ64fZpzz"
      },
      "source": [
        "### 1.1. Chain of Density (Multilingual)\n",
        "Generate increasingly dense summaries in any specified language through iterative refinement while maintaining semantic accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ku2VJunbZo7y"
      },
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt_title = \"chain-of-density-multilingual\"\n",
        "\n",
        "chain_density_multilingual = \"\"\"\n",
        "Article: {ARTICLE}\n",
        "Language: {LANGUAGE}\n",
        "\n",
        "You will generate increasingly concise, entity-dense summaries of the above article in the specified language.\n",
        "\n",
        "Repeat the following 2 steps 5 times.\n",
        "\n",
        "Step 1. Identify 1-3 informative entities (\";\" delimited) from the article which are missing from the previously generated summary.\n",
        "Step 2. Write a new, denser summary of identical length which covers every entity and detail from the previous summary plus the missing entities.\n",
        "\n",
        "A missing entity is:\n",
        "- relevant to the main story,\n",
        "- specific yet concise (100 words or fewer),\n",
        "- novel (not in the previous summary),\n",
        "- faithful (present in the article),\n",
        "- anywhere (can be located anywhere in the article).\n",
        "\n",
        "Guidelines:\n",
        "- The first summary should be long (8-10 sentences, ~200 words) yet highly non-specific\n",
        "- Make every word count: rewrite the previous summary to improve flow\n",
        "- Make space with fusion, compression, and removal of uninformative phrases\n",
        "- The summaries should become highly dense and concise yet self-contained\n",
        "- Missing entities can appear anywhere in the new summary\n",
        "- Never drop entities from the previous summary\n",
        "\n",
        "OUTPUT FORMAT:\n",
        "[\n",
        "    {\n",
        "        \"Missing_Entities\": str,\n",
        "        \"Denser_Summary\": str\n",
        "    }\n",
        "]\n",
        "\n",
        "Provide the output in the specified language: {LANGUAGE}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(chain_density_multilingual)\n",
        "\n",
        "# Usage Example:\n",
        "response = chain_density_multilingual.format(\n",
        "    ARTICLE=\"Your article text here\", LANGUAGE=\"Spanish\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdRjE4nIZvJN"
      },
      "source": [
        "### 1.2. Chain of Density Map (Multilingual)\n",
        "\n",
        " Create mapped summaries with increasing density in any specified language, focusing on key entity extraction and relationship mapping.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CUIIIcsZl2C"
      },
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt_title = \"chain-of-density-map-multilingual\"\n",
        "\n",
        "chain_density_map_multilingual = \"\"\"\n",
        "Article: {ARTICLE}\n",
        "Language: {LANGUAGE}\n",
        "\n",
        "You will generate increasingly concise, entity-dense summaries of the above article in the specified language.\n",
        "\n",
        "Repeat the following 2 steps 3 times.\n",
        "\n",
        "Step 1. Identify 1-3 informative entities (\";\" delimited) from the article which are missing from the previous summary.\n",
        "Step 2. Write a new, denser summary of identical length covering all previous entities plus new ones.\n",
        "\n",
        "A missing entity is:\n",
        "- relevant to the main story,\n",
        "- specific yet concise (100 words or fewer),\n",
        "- novel (not in the previous summary),\n",
        "- faithful (present in the article),\n",
        "- anywhere (can be located anywhere in the article).\n",
        "\n",
        "Guidelines:\n",
        "- First summary: 8-10 sentences (~200 words), non-specific with fillers\n",
        "- Optimize word usage and improve flow\n",
        "- Remove uninformative phrases\n",
        "- Maintain density and self-containment\n",
        "- Preserve all previous entities\n",
        "\n",
        "OUTPUT FORMAT:\n",
        "Text format for \"Missing Entities\" and \"Denser_Summary\"\n",
        "\n",
        "Provide the output in the specified language: {LANGUAGE}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(chain_density_map_multilingual)\n",
        "\n",
        "# Usage Example:\n",
        "response_map = chain_density_map_multilingual.format(\n",
        "    ARTICLE=\"Your article text here\", LANGUAGE=\"Japanese\"  # or any other language\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ9zblwWWyZb"
      },
      "source": [
        "### 2. Key Information Extraction\n",
        "\n",
        "Extract and structure critical information from various document types with high precision and consistency.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "cVW1iVKQXBT7",
        "outputId": "63c7c080-194d-4614-878a-4d42948e85d1"
      },
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_title = \"key-information-extraction\"\n",
        "\n",
        "extraction_prompt = \"\"\"\n",
        "Extract key information from the provided document according to these specifications:\n",
        "\n",
        "INPUT:\n",
        "- Document: {document}\n",
        "- Target Fields: {fields}\n",
        "- Context Requirements: {context}\n",
        "\n",
        "EXTRACTION REQUIREMENTS:\n",
        "1. Identify specified data points\n",
        "2. Maintain contextual relationships\n",
        "3. Validate extracted information\n",
        "4. Format according to schema\n",
        "\n",
        "OUTPUT FORMAT:\n",
        "{\n",
        "    \"extracted_data\": dict,\n",
        "    \"confidence_scores\": dict,\n",
        "    \"validation_results\": dict,\n",
        "    \"metadata\": dict\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(extraction_prompt)\n",
        "hub.push(prompt_title, prompt, new_repo_is_public=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw0SbKcKD7xd"
      },
      "source": [
        "\n",
        "### 3. Metadata Tagging\n",
        "Automatically generate relevant tags and metadata to enhance content organization and searchability.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wvAw2hW-Y_yH",
        "outputId": "9f28672a-0d08-438c-b64a-6c7c3fd9d347"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://smith.langchain.com/prompts/metadata-tagger/9bf50dec?organizationId=f2bffb3c-dd45-53ac-b23b-5d696451d11c'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain import hub\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_title = \"metadata-tagger\"\n",
        "\n",
        "metadata_prompt = \"\"\"\n",
        "Generate comprehensive metadata tags for the given content:\n",
        "\n",
        "CONTENT PARAMETERS:\n",
        "- Type: {content_type}\n",
        "- Domain: {domain}\n",
        "- Context: {context}\n",
        "\n",
        "TAGGING REQUIREMENTS:\n",
        "1. Generate relevant tags\n",
        "2. Create hierarchical categories\n",
        "3. Identify key topics\n",
        "4. Map relationships\n",
        "5. Optimize for search\n",
        "\n",
        "OUTPUT FORMAT:\n",
        "{\n",
        "    \"primary_tags\": list,\n",
        "    \"categories\": dict,\n",
        "    \"relationships\": dict,\n",
        "    \"search_terms\": list\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(metadata_prompt)\n",
        "hub.push(prompt_title, prompt, new_repo_is_public=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4sJJp68D7xe"
      },
      "source": [
        "---\n",
        "## Specialized Prompts\n",
        "\n",
        "### 1. RAG Prompts\n",
        "\n",
        "### 1.1. RAG Document Analysis\n",
        "\n",
        "Process and answer questions based on retrieved document contexts with high accuracy and relevance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNn4Hc95ars2",
        "outputId": "94e67ea9-9bd5-4d5f-9f03-1e145852cbb0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"You are a precise and helpful AI assistant specializing in question-answering tasks based on provided context.\\nYour primary task is to:\\n1. Analyze the provided context thoroughly\\n2. Answer questions using ONLY the information from the context\\n3. Preserve technical terms and proper nouns exactly as they appear\\n4. If the answer cannot be found in the context, respond with: 'The provided context does not contain information to answer this question.'\\n5. Format responses in clear, readable paragraphs with relevant examples when available\\n6. Focus on accuracy and clarity in your responses\\n\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='#Question:\\n{question}\\n\\n#Context:\\n{context}\\n\\n#Answer:\\nPlease provide a focused, accurate response that directly addresses the question using only the information from the provided context.'), additional_kwargs={})])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain import hub\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt_title = \"rag-document-analysis\"\n",
        "\n",
        "system = \"\"\"You are a precise and helpful AI assistant specializing in question-answering tasks based on provided context.\n",
        "Your primary task is to:\n",
        "1. Analyze the provided context thoroughly\n",
        "2. Answer questions using ONLY the information from the context\n",
        "3. Preserve technical terms and proper nouns exactly as they appear\n",
        "4. If the answer cannot be found in the context, respond with: 'The provided context does not contain information to answer this question.'\n",
        "5. Format responses in clear, readable paragraphs with relevant examples when available\n",
        "6. Focus on accuracy and clarity in your responses\n",
        "\"\"\"\n",
        "\n",
        "human = \"\"\"#Question:\n",
        "{question}\n",
        "\n",
        "#Context:\n",
        "{context}\n",
        "\n",
        "#Answer:\n",
        "Please provide a focused, accurate response that directly addresses the question using only the information from the provided context.\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])\n",
        "\n",
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "saj8jooLD7xe",
        "outputId": "506cffcd-4cc4-4908-9525-bf86b22ad5f6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://smith.langchain.com/prompts/rag-document-analysis/f7a42fa8?organizationId=f2bffb3c-dd45-53ac-b23b-5d696451d11c'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hub.push(prompt_title, prompt, new_repo_is_public=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd7KRy1-D7xe"
      },
      "source": [
        "### 1.2. RAG with Source Attribution\n",
        "\n",
        "Enhanced RAG implementation with detailed source tracking and citation for improved accountability and verification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "JTXOYs0ma5mu",
        "outputId": "b9dffe05-e619-4669-a8a6-660c42ce8c49"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://smith.langchain.com/prompts/rag-with-sources/67246bf3?organizationId=f2bffb3c-dd45-53ac-b23b-5d696451d11c'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain import hub\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt_title = \"rag-with-sources\"\n",
        "\n",
        "system = \"\"\"You are a precise and thorough AI assistant that provides well-documented answers with source attribution.\n",
        "Your responsibilities include:\n",
        "1. Analyzing provided context thoroughly\n",
        "2. Generating accurate answers based solely on the given context\n",
        "3. Including specific source references for each key point\n",
        "4. Preserving technical terminology exactly as presented\n",
        "5. Maintaining clear citation format [source: page/document]\n",
        "6. If information is not found in the context, state: 'The provided context does not contain information to answer this question.'\n",
        "\n",
        "Format your response as:\n",
        "1. Main Answer\n",
        "2. Sources Used (with specific locations)\n",
        "3. Confidence Level (High/Medium/Low)\"\"\"\n",
        "\n",
        "human = \"\"\"#Question:\n",
        "{question}\n",
        "\n",
        "#Context:\n",
        "{context}\n",
        "\n",
        "#Answer:\n",
        "Please provide a detailed response with source citations using only information from the provided context.\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])\n",
        "PROMPT_OWNER = \"eun\"\n",
        "hub.push(f\"{PROMPT_OWNER}/{prompt_title}\", prompt, new_repo_is_public=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7OCErMJD7xe"
      },
      "source": [
        "### 2. LLM Response Evaluation\n",
        "\n",
        "Comprehensive evaluation of LLM responses based on multiple quality metrics with detailed scoring methodology.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "v7-eJ3XOa9dM"
      },
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_title = \"llm-response-evaluation\"\n",
        "\n",
        "evaluation_prompt = \"\"\"Evaluate the LLM's response based on the following criteria:\n",
        "\n",
        "INPUT:\n",
        "Question: {question}\n",
        "Context: {context}\n",
        "LLM Response: {answer}\n",
        "\n",
        "EVALUATION CRITERIA:\n",
        "1. Accuracy (0-10)\n",
        "- Perfect (10): Completely accurate, perfectly aligned with context\n",
        "- Good (7-9): Minor inaccuracies\n",
        "- Fair (4-6): Some significant inaccuracies\n",
        "- Poor (0-3): Major inaccuracies or misalignment\n",
        "\n",
        "2. Completeness (0-10)\n",
        "- Perfect (10): Comprehensive coverage of all relevant points\n",
        "- Good (7-9): Covers most important points\n",
        "- Fair (4-6): Missing several key points\n",
        "- Poor (0-3): Critically incomplete\n",
        "\n",
        "3. Context Relevance (0-10)\n",
        "- Perfect (10): Optimal use of context\n",
        "- Good (7-9): Good use with minor omissions\n",
        "- Fair (4-6): Partial use of relevant context\n",
        "- Poor (0-3): Poor context utilization\n",
        "\n",
        "4. Clarity (0-10)\n",
        "- Perfect (10): Exceptionally clear and well-structured\n",
        "- Good (7-9): Clear with minor issues\n",
        "- Fair (4-6): Somewhat unclear\n",
        "- Poor (0-3): Confusing or poorly structured\n",
        "\n",
        "SCORING METHOD:\n",
        "1. Calculate individual scores\n",
        "2. Compute weighted average:\n",
        "   - Accuracy: 40%\n",
        "   - Completeness: 25%\n",
        "   - Context Relevance: 25%\n",
        "   - Clarity: 10%\n",
        "3. Normalize to 0-1 scale\n",
        "\n",
        "OUTPUT FORMAT:\n",
        "{\n",
        "    \"individual_scores\": {\n",
        "        \"accuracy\": float,\n",
        "        \"completeness\": float,\n",
        "        \"context_relevance\": float,\n",
        "        \"clarity\": float\n",
        "    },\n",
        "    \"weighted_score\": float,\n",
        "    \"normalized_score\": float,\n",
        "    \"evaluation_notes\": string\n",
        "}\n",
        "\n",
        "Return ONLY the normalized_score as a decimal between 0 and 1.\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(evaluation_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hQt-fczC_V2"
      },
      "source": [
        "---\n",
        "## Professional Domain Prompts\n",
        "\n",
        "Each professional domain prompt is carefully crafted to address specific industry needs and requirements.\n",
        "\n",
        "This part requires optimization of prompts, especially according to domain data and format. Therefore, it is recommended that you test multiple prompts with Playground on websites such as OpenAI or Anthropic and use the most appropriate prompts. Below is an example of prompts in each field.\n",
        "\n",
        "### 1. Academic Research Analysis Prompt\n",
        "```python\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "As an expert academic researcher, analyze the academic content with:\n",
        "\n",
        "INPUT:\n",
        "- Content Type: {content_type}\n",
        "- Field of Study: {field}\n",
        "- Analysis Depth: {depth}\n",
        "\n",
        "ANALYZE:\n",
        "1. Research methodology and design\n",
        "2. Key findings and significance\n",
        "3. Theoretical framework\n",
        "4. Statistical validity\n",
        "5. Study limitations\n",
        "6. Future directions\n",
        "\n",
        "OUTPUT FORMAT:\n",
        "{\n",
        "    \"executive_summary\": str,\n",
        "    \"methodology_analysis\": dict,\n",
        "    \"findings_analysis\": dict,\n",
        "    \"quality_assessment\": dict\n",
        "}\n",
        "\"\"\"\n",
        "```\n",
        "\n",
        "### 2. Clinical Case Analysis Prompt\n",
        "```python\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "As a medical professional, analyze clinical cases with:\n",
        "\n",
        "INPUT:\n",
        "- Patient Information: {patient_data}\n",
        "- Clinical Notes: {clinical_notes}\n",
        "\n",
        "PROVIDE:\n",
        "1. Clinical Assessment\n",
        "2. Diagnostic Process\n",
        "3. Treatment Plan\n",
        "4. Risk Assessment\n",
        "\n",
        "OUTPUT FORMAT:\n",
        "{\n",
        "    \"clinical_summary\": str,\n",
        "    \"differential_diagnosis\": list,\n",
        "    \"treatment_plan\": dict,\n",
        "    \"risk_assessment\": dict\n",
        "}\n",
        "\"\"\"\n",
        "```\n",
        "\n",
        "### 3. Market Research Analysis Prompt\n",
        "```python\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "As a market research analyst, analyze:\n",
        "\n",
        "PARAMETERS:\n",
        "- Industry: {industry}\n",
        "- Market Segment: {segment}\n",
        "- Region: {region}\n",
        "- Time Period: {time_period}\n",
        "\n",
        "COMPONENTS:\n",
        "1. Market Overview\n",
        "2. Competitive Analysis\n",
        "3. Customer Analysis\n",
        "4. SWOT Analysis\n",
        "5. Financial Analysis\n",
        "6. Recommendations\n",
        "\n",
        "OUTPUT FORMAT:\n",
        "{\n",
        "    \"market_overview\": dict,\n",
        "    \"competitive_landscape\": dict,\n",
        "    \"customer_insights\": dict,\n",
        "    \"strategic_recommendations\": list\n",
        "}\n",
        "\"\"\"\n",
        "```\n",
        "\n",
        "### 4. Educational Content Development Prompt\n",
        "```python\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "As an educational content developer, create:\n",
        "\n",
        "PARAMETERS:\n",
        "- Subject: {subject}\n",
        "- Grade Level: {grade_level}\n",
        "- Learning Objectives: {objectives}\n",
        "- Duration: {duration}\n",
        "\n",
        "DELIVER:\n",
        "1. Course Structure\n",
        "2. Learning Materials\n",
        "3. Assessment Components\n",
        "4. Differentiation Strategies\n",
        "5. Support Resources\n",
        "\n",
        "OUTPUT FORMAT:\n",
        "{\n",
        "    \"course_outline\": dict,\n",
        "    \"lesson_plans\": list,\n",
        "    \"assessments\": dict,\n",
        "    \"support_resources\": dict\n",
        "}\n",
        "\"\"\"\n",
        "```\n",
        "\n",
        "### 5. Legal Document Analysis Prompt\n",
        "```python\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "As a legal professional, analyze:\n",
        "\n",
        "PARAMETERS:\n",
        "- Document Type: {doc_type}\n",
        "- Jurisdiction: {jurisdiction}\n",
        "- Legal Domain: {domain}\n",
        "\n",
        "ANALYZE:\n",
        "1. Document Overview\n",
        "2. Key Provisions\n",
        "3. Risk Assessment\n",
        "4. Compliance Check\n",
        "5. Recommendations\n",
        "\n",
        "OUTPUT FORMAT:\n",
        "{\n",
        "    \"document_summary\": str,\n",
        "    \"key_provisions\": dict,\n",
        "    \"risk_analysis\": dict,\n",
        "    \"recommendations\": list\n",
        "}\n",
        "\"\"\"\n",
        "```\n",
        "\n",
        "### 6. UX Research Analysis Prompt\n",
        "```python\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "As a UX researcher, analyze:\n",
        "\n",
        "PARAMETERS:\n",
        "- Research Type: {research_type}\n",
        "- Product/Service: {product}\n",
        "- User Segment: {segment}\n",
        "- Research Goals: {goals}\n",
        "\n",
        "PROVIDE:\n",
        "1. User Behavior Analysis\n",
        "2. Usability Assessment\n",
        "3. User Experience Mapping\n",
        "4. Accessibility Evaluation\n",
        "5. Recommendations\n",
        "\n",
        "OUTPUT FORMAT:\n",
        "{\n",
        "    \"behavioral_insights\": dict,\n",
        "    \"usability_metrics\": dict,\n",
        "    \"experience_mapping\": dict,\n",
        "    \"design_recommendations\": list\n",
        "}\n",
        "\"\"\"\n",
        "```\n",
        "\n",
        "### 7. Environmental Impact Assessment Prompt\n",
        "```python\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "As an environmental specialist, assess:\n",
        "\n",
        "PARAMETERS:\n",
        "- Project Type: {project_type}\n",
        "- Location: {location}\n",
        "- Scale: {scale}\n",
        "- Duration: {duration}\n",
        "\n",
        "ANALYZE:\n",
        "1. Environmental Baseline\n",
        "2. Impact Analysis\n",
        "3. Resource Assessment\n",
        "4. Mitigation Strategies\n",
        "5. Monitoring Plan\n",
        "\n",
        "OUTPUT FORMAT:\n",
        "{\n",
        "    \"assessment_summary\": str,\n",
        "    \"impact_analysis\": dict,\n",
        "    \"mitigation_plan\": dict,\n",
        "    \"monitoring_framework\": dict\n",
        "}\n",
        "\"\"\"\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py-test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
