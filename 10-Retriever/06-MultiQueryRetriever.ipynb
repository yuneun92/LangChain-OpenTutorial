{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46198a85",
   "metadata": {},
   "source": [
    "# MultiQueryRetriever\n",
    "\n",
    "- Author: [hong-seongmin](https://github.com/hong-seongmin)\n",
    "- Design: \n",
    "- Peer Review: [Hye-yoon](https://github.com/Hye-yoonJeong),[Wooseok-Jeong](https://github.com/jeong-wooseok)\n",
    "- This is a part of [LangChain OpenTutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-4/sub-graph.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239937-lesson-2-sub-graphs)\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "`MultiQueryRetriever` offers an automated solution to enhance distance-based vector database searches by generating multiple queries from diverse perspectives using a Language Learning Model (LLM). This approach addresses the challenges of manual prompt tuning and improves the quality and comprehensiveness of search results without extensive model fine-tuning.\n",
    "\n",
    "- **Automated Prompt Tuning**: Leverages an LLM to create multiple queries from various viewpoints based on a single user input, eliminating the need for manual adjustments and prompt engineering.\n",
    "- **Comprehensive Document Retrieval**: Executes searches for each generated query and combines the unique documents from all queries, resulting in a larger and more relevant set of documents.\n",
    "- **Enhanced Search Robustness**: Mitigates the limitations of distance-based searches by capturing subtle differences and deeper meanings in data, ensuring more accurate and contextually relevant search outcomes.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [Usage](#usage)\n",
    "- [How to use the LCEL Chain](#how-to-use-the-LCEL-Chain)\n",
    "\n",
    "### References\n",
    "\n",
    "- [LangChain Documentation: Few-shot prompting](https://python.langchain.com/docs/concepts/few_shot_prompting)\n",
    "- [How to better prompt when doing SQL question-answering](https://python.langchain.com/docs/how_to/sql_prompting/#few-shot-examples)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "330d1c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-opentutorial in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.0.3)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -angchain-community (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Error parsing dependencies of torchsde: .* suffix can only be used with `==` or `!=` operators\n",
      "    numpy (>=1.19.*) ; python_version >= \"3.7\"\n",
      "           ~~~~~~~^\n",
      "WARNING: Ignoring invalid distribution -angchain-community (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -angchain-community (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef9fdc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langchain\",\n",
    "        \"langchain_core\",\n",
    "        \"langchain_openai\",\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ee62e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration file to manage API keys as environment variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API key information\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a6a2728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"06-Multi-Query-Retriever\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c14b5b",
   "metadata": {},
   "source": [
    "## Building a Vector Database with LangChain\n",
    "\n",
    "This section demonstrates how to set up a simple vector database using LangChain components, load documents from a URL, and perform a search query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dae75cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a sample vector DB\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load a blog post\n",
    "loader = WebBaseLoader(\n",
    "    \"https://python.langchain.com/docs/introduction/\", encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "# Split documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs = loader.load_and_split(text_splitter)\n",
    "\n",
    "# Define embedding\n",
    "openai_embedding = OpenAIEmbeddings()\n",
    "\n",
    "# Create the vector DB\n",
    "db = FAISS.from_documents(docs, openai_embedding)\n",
    "\n",
    "# Create a retriever\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "# Document search\n",
    "query = \"Please explain the key features and architecture of the LangChain framework.\"\n",
    "relevant_docs = retriever.invoke(query)\n",
    "\n",
    "# Print the number of retrieved documents\n",
    "len(relevant_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d88fd7",
   "metadata": {},
   "source": [
    "Print the content of one of the retrieved documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8ea9548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 강력한 도구로서, Assistant에게 사용자 정의 함수를 지정할 수 있습니다. 이는 Chat Completions API에서의 함수 호출과 매우 유사합니다.\n",
      "\n",
      "\n",
      "Function calling(함수 호출) 도구를 사용하면 Assistant 에게 사용자 정의 함수 를 설명하여 호출해야 하는 함수를 인자와 함께 지능적으로 반환하도록 할 수 있습니다.\n",
      "\n",
      "\n",
      "Assistant API는 실행 중에 함수를 호출할 때 실행을 일시 중지하며, 함수 호출 결과를 다시 제공하여 Run 실행을 계속할 수 있습니다. (이는 사용자 피드백을 받아 재게할 수 있는 의미이기도 합니다. 아래 튜토리얼에서 상세히 다룹니다).\n"
     ]
    }
   ],
   "source": [
    "# Print document #1\n",
    "print(relevant_docs[1].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f3224e",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "Simply specify the LLM to be used in `MultiQueryRetriever` and pass the query, and the retriever will handle the rest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1637815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# Initialize the ChatOpenAI language model with temperature set to 0.\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "\n",
    "multiquery_retriever = MultiQueryRetriever.from_llm(  # Initialize the MultiQueryRetriever using the language model.\n",
    "    # Pass the vector database retriever and the language model.\n",
    "    retriever=db.as_retriever(),\n",
    "    llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd0b647",
   "metadata": {},
   "source": [
    "Below is code that you can run to debug the intermediate process of generating multiple queries.\n",
    "\n",
    "First, we retrieve the `\"langchain.retrievers.multi_query\"` logger.\n",
    "\n",
    "This is done using the `logging.getLogger()` function. Then, we set the logger's log level to `INFO`, so that only log messages at the `INFO` level or above are printed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "901d1749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging settings for the query\n",
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfda8ebb",
   "metadata": {},
   "source": [
    "This code uses the `invoke` method of the `retriever_from_llm` object to search for documents relevant to the given `question`.\n",
    "\n",
    "The retrieved documents are stored in the variable `unique_docs`, and checking the length of this variable lets you see how many relevant documents were found. Through this process, you can effectively locate information related to the user's question and assess how much of it is available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2e305f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. What are the steps to implement Functions using the OpenAI Assistant API?  ', '2. Can you explain the process of utilizing Functions within the OpenAI Assistant API?  ', '3. What should I know about working with Functions in the OpenAI Assistant API?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============\n",
      "Number of retrieved documents: 5\n",
      "===============\n",
      "OpenAI의 새로운 Assistants API는 대화와 더불어 강력한 도구 접근성을 제공합니다. 본 튜토리얼은 OpenAI Assistants API를 활용하는 내용을 다룹니다. 특히, Assistant API 가 제공하는 도구인 Code Interpreter, Retrieval, Functions 를 활용하는 방법에 대해 다룹니다. 이와 더불어 파일을 업로드 하는 내용과 사용자의 피드백을 제출하는 내용도 튜토리얼 말미에 포함하고 있습니다.\n",
      "\n",
      "\n",
      "\n",
      "주요내용\n"
     ]
    }
   ],
   "source": [
    "# Define the question\n",
    "question = \"Please explain the key features and architecture of the LangChain framework.\"\n",
    "# Document search\n",
    "relevant_docs = multiquery_retriever.invoke(question)\n",
    "\n",
    "# Return the number of unique documents retrieved.\n",
    "print(\n",
    "    f\"===============\\nNumber of retrieved documents: {len(relevant_docs)}\",\n",
    "    end=\"\\n===============\\n\",\n",
    ")\n",
    "\n",
    "# Print the content of the retrieved documents.\n",
    "print(relevant_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81695892",
   "metadata": {},
   "source": [
    "## How to use the LCEL Chain\n",
    "\n",
    "- Define a custom prompt, then create a Chain with that prompt.\n",
    "- When the Chain receives a user question (in the following example), it generates 5 questions, and returns the 5 generated questions separated by \"\\n\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ab98687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OpenAI Assistant API에서 함수 사용 방법에 대해 알려주세요.\\n\\nOpenAI Assistant API에서 함수 활용에 대한 정보를 제공해 주세요.\\n\\nOpenAI Assistant API에서 함수 사용법에 대해 설명해 주세요.\\n\\nOpenAI Assistant API에서 함수 기능을 사용하는 방법을 알려주세요.\\n\\nOpenAI Assistant API에서 함수 사용에 관한 내용을 알고 싶습니다.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Define the prompt template (written to generate 5 questions)\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an AI language model assistant. \n",
    "Your task is to generate five different versions of the given user question to retrieve relevant documents from a vector database. \n",
    "By generating multiple perspectives on the user question, your goal is to help the user overcome some of the limitations of the distance-based similarity search. \n",
    "Your response should be a list of values separated by new lines, eg: `foo\\nbar\\nbaz\\n`\n",
    "\n",
    "#ORIGINAL QUESTION: \n",
    "{question}\n",
    "\n",
    "#Answer in Korean:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Create an instance of the language model.\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "\n",
    "# Create the LLMChain.\n",
    "custom_multiquery_chain = (\n",
    "    {\"question\": RunnablePassthrough()} | prompt | llm | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Define the question.\n",
    "question = \"Please explain the key features and architecture of the LangChain framework.\"\n",
    "\n",
    "# Execute the chain and check the generated multiple queries.\n",
    "multi_queries = custom_multiquery_chain.invoke(question)\n",
    "# Check the result (5 generated questions)\n",
    "multi_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6403eb",
   "metadata": {},
   "source": [
    "You can pass the previously created Chain to `MultiQueryRetriever` to perform retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f3cac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiquery_retriever = MultiQueryRetriever.from_llm(\n",
    "    llm=custom_multiquery_chain, retriever=db.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086076bb",
   "metadata": {},
   "source": [
    "Use `MultiQueryRetriever` to search documents and check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6eaffe30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['OpenAI Assistant API에서 함수 사용 방법에 대해 알려주세요.  ', 'OpenAI Assistant API에서 함수 활용에 대한 정보를 제공해 주세요.  ', 'OpenAI Assistant API에서 함수 사용법에 대해 설명해 주실 수 있나요?  ', 'OpenAI Assistant API의 함수 사용에 대해 자세히 알고 싶습니다.  ', 'OpenAI Assistant API에서 함수 기능을 사용하는 방법은 무엇인가요?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============\n",
      "Number of retrieved documents: 5\n",
      "===============\n",
      "OpenAI의 새로운 Assistants API는 대화와 더불어 강력한 도구 접근성을 제공합니다. 본 튜토리얼은 OpenAI Assistants API를 활용하는 내용을 다룹니다. 특히, Assistant API 가 제공하는 도구인 Code Interpreter, Retrieval, Functions 를 활용하는 방법에 대해 다룹니다. 이와 더불어 파일을 업로드 하는 내용과 사용자의 피드백을 제출하는 내용도 튜토리얼 말미에 포함하고 있습니다.\n",
      "\n",
      "\n",
      "\n",
      "주요내용\n"
     ]
    }
   ],
   "source": [
    "# Result\n",
    "relevant_docs = multiquery_retriever.invoke(question)\n",
    "\n",
    "# Return the number of unique documents retrieved.\n",
    "print(\n",
    "    f\"===============\\nNumber of retrieved documents: {len(relevant_docs)}\",\n",
    "    end=\"\\n===============\\n\",\n",
    ")\n",
    "\n",
    "# Print the content of the retrieved documents.\n",
    "print(relevant_docs[0].page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
